# Google Photos album to Photoprism Album
*A somewhat involved script to transfer a Google Photos album to a new Photoprism album*

Photoprism does not yet support transferring albums from Google Photos.  Once a library
has been fully transferred, this script will scrape the necessary data from a Google
Takeout of an album and use it to generate a new Photoprism album without duplicating any
files.

This is my fork of [inthreedee's original script][upstream], and I am very
grateful to them for doing all the annoying API work for me and providing a
solid base to work from. This fork was inspired by and incorporates
[StephenBrown2's suggestion][insight] to look up files via their SHA-1 hash,
which simplifies and speeds things up considerably - look ma, no sidecar
directory! It also includes various usability improvements such as batching
photo IDs, extracting titles and descriptions from Google's metadata, reading
configuration from a file or interactive prompting, and importing an entire
export in one go.

[upstream]: https://github.com/inthreedee/photoprism-transfer-album
[insight]: https://github.com/photoprism/photoprism/issues/869#issuecomment-779488150

## To use this script:

1. Download the desired album via Google Takeout.
2. (Optional) Add a config.ini, see below
3. Run the script. It will prompt interactively for any missing config. If given a
   command line parameter, it treats it as a directory to process, otherwise it will look
   in the current working directory for any albums it can find.

## Config File

The script will prompt interactively for any information it is missing, but you can provide
it programatically either by providing environment variables, or placing a `config.ini` file
in the directory you are running the script from. An example `config.ini`:

```
API_USERNAME=admin
API_PASSWORD=your really good password
SITE_URL=https://photos.example.com
```

If you're setting environment variables, it's the same values as the config file.

## What it does:

1. It creates a new Photoprism album with the title and description from the album's
   `metadata.json`.
2. It scans all files in the album's directory, hashing any non-JSON files.
3. It looks up each file in the database by its hash using Photoprism's files API.
4. If it finds a match, it adds the photo's UID to the current album's list.
5. When all files or processed, or when it has gathered 999 files, an API request is sent
   to the server to add the gathered photos to the album.

## Notes:

- This script can be run either in a single album directory, or in the base Google Photos
directory. If it finds a `metadata.json` in the given directory it will import it as a
single album, otherwise it will try to import each subdirectory as an album.
- As written, the script will ignore auto-generated albums - specifically, albums without
titles, albums that start with a `YYYY-MM-DD` date or `Hangout:`, or albums with a
description indicating they are autogenerated. If you would like to import any of these,
you can comment out the relevant if statement in the script (that is, add a `#` at the
beginning of each line from the if up through the next fi below the appropriate comment).
- Because there are a lot of API calls involved (one for each file!) it's fastest to run
this on the machine that is running PhotoPrism, but it will also work just fine if you
run it on a local copy of your Google Takeout while accessing your PhotoPrism instance
over the web.
- This script should be pretty safe, it does no modifications of the filesystem, and only
  creates things using the API - worst case, you have a bunch of broken albums you have to
delete. That said, as always, use at your own risk, peek under the hood if you're
concerned, etc.
- It should also be robust and efficient - it successfully processed my Google Photos dump
with 35,000+ photos and 60 albums with up to hundreds of photos in the space of a few
minutes. The batching logic has been tested with 1000+ placeholder files, but not with an
actual album. If you have such an album, let me know if it worked or not!
- The script is _very_ verbose - you can comment out the bodies of the `log` and `logexec`
functions if you want less noise, or just pipe stderr to /dev/null.

## Notes you probably don't care about:

- There's an extra flag available that isn't documented (except here): you can run it with
`-c <filename>` as the first arguments, and it will run in a dry-run mode, dumping all of
the commands it would have run into the specified file, so you can take a peek. Note that
this file will not actually work, because you have to actually create the album to get the
album ID to then add the album photos, but if you want to make sure it seems like it's
doing what you want, knock yourself out.
- There's a lot of weird bash nonsense going on to log the commands that we're running -
it should still be pretty compatible with any remotely modern bash-compatible shell, but
if the curl commands seem like they're getting screwed up, you can remove the `logexec`
from the `api_call()` method, and it will bypass the most arcane bash stuff. You can also
walk disable the file batching and submit the album files one at a time to bypass more
complicated stuff, there's a comment block about that in the main loop.
- Yes, this script parses JSON with awk and constructs JSON with bash loops. It works
fine. There's a commented-out line to do most parsing with jq if it makes you feel better.
